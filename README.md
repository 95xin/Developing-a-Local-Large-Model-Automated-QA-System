# Voice & Text Question-Answering System

An intelligent voice/text Q&A system based on Flask, supporting both voice and text input. It integrates speech recognition, automatic translation, and AI question-answering capabilities, utilizing Whisper for speech recognition and locally deployed DeepSeek-R1 large model for generating responses.

## Features

- üé§ **Voice Input**: Real-time voice recording and recognition
- üîÑ **Auto Translation**: Bidirectional Chinese-English translation
  - Chinese input automatically translated to English
  - English input automatically translated to Chinese
- ‚å®Ô∏è **Text Input**: Direct text-based question input
- ü§ñ **AI Response**: Intelligent answers generated by DeepSeek-R1 model
- üé® **Modern UI**: Clean and elegant interface design with dynamic emoji effects
- üîÑ **Real-time Feedback**: Instant feedback for recording and processing status
- ‚ú® **Interactive Effects**: Cute emoji animations following mouse movement

## Tech Stack

- **Backend**: Flask
- **Frontend**: HTML, CSS, JavaScript
- **Speech Recognition**: OpenAI Whisper
- **AI Model**: DeepSeek-R1 (running via Ollama)
- **Audio Processing**: FFmpeg
- **Translation**: DeepSeek-R1

## System Requirements

- Python 3.x
- FFmpeg (for audio conversion)
- Ollama (with DeepSeek-R1 model installed)
- Modern browser (supporting MediaRecorder API)
- Microphone device (for voice input)

## Installation

1. Clone the repository
```bash
git clone https://github.com/95xin/Developing-a-Local-Large-Model-Automated-QA-System.git
cd Developing-a-Local-Large-Model-Automated-QA-System
```

2. Install Python dependencies
```bash
pip install flask whisper torch
```

3. Install Ollama and download DeepSeek-R1 model
```bash
# Install Ollama (choose method based on your OS)
# macOS
brew install ollama

# Download model
ollama pull deepseek-r1:1.5b
```

4. Install FFmpeg (if not already installed)
```bash
# macOS
brew install ffmpeg

# Ubuntu
sudo apt-get install ffmpeg
```

5. Run the application
```bash
python app.py
```

6. Access the application
Open your browser and visit `http://localhost:5000`

## Usage Guide

1. **Voice Input Mode**:
   - Click "Start Recording" to begin
   - Speak your question (supports both Chinese and English)
   - Click "Stop Recording" to end
   - The system will automatically:
     - Recognize your speech
     - Provide translation (Chinese to English or vice versa)
     - Generate AI response

2. **Text Input Mode**:
   - Type your question in the text box
   - Click "Generate Answer"
   - System will generate AI response

## Project Structure
```
‚îú‚îÄ‚îÄ app.py              # Flask application main file
‚îú‚îÄ‚îÄ static/             # Static resources directory
‚îÇ   ‚îî‚îÄ‚îÄ temp_audio.*    # Temporary audio files
‚îú‚îÄ‚îÄ templates/          # Template directory
‚îÇ   ‚îî‚îÄ‚îÄ index.html      # Frontend page template
‚îî‚îÄ‚îÄ README.md          # Project documentation
```

## Special Notes

- Speech recognition uses Whisper's base model, supporting multiple languages
- Translation and Q&A powered by DeepSeek-R1 model, supporting Chinese-English bidirectional translation
- All AI processing is done locally, no internet connection required
- Interface features real-time dynamic effects for enhanced user experience

## Changelog

### 2024-02-23
- Added Chinese-English automatic translation
- Enhanced UI with dynamic emoji effects
- Improved error handling and user feedback
- Optimized AI response display

## Contributing

Contributions via Issues and Pull Requests are welcome. Before submitting a PR, please ensure:
1. Code follows project coding standards
2. New features are properly tested
3. Documentation is updated accordingly

## License

MIT License
